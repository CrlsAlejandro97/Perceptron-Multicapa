{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3637cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from function import lineal, sigmoide, derivate_sigmoide, error, derivate_lineal\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8d5462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializamos los pesos de la Capa 1\n",
    "w = np.random.random(500)\n",
    "w11 = w[:100]\n",
    "w12 = w[100:200]\n",
    "w13 = w[200:300]\n",
    "w14 = w[300:400]\n",
    "w15 = w[400:500]\n",
    "W1=[w11,w12,w13,w14,w15]\n",
    "\n",
    "#Inicializamos los pesos de la Capa 2\n",
    "w = np.random.random(25)\n",
    "w21 = w[:5]\n",
    "w22 = w[5:10]\n",
    "w23 = w[10:15]\n",
    "w24 = w[15:20]\n",
    "w25 = w[20:25]\n",
    "W2 = [w21,w22,w23,w24,w25] \n",
    "\n",
    "#Incializamos los pesos de la Capa 3\n",
    "w = np.random.random(15)\n",
    "w31 = w[:5]\n",
    "w32 = w[5:10]\n",
    "w33 = w[10:15]\n",
    "W3 = [w31,w32,w33]\n",
    "\n",
    "#Bias\n",
    "b = random.random()\n",
    "\n",
    "#Factor de aprendizaje\n",
    "alfa = random.random()\n",
    "\n",
    "#Codificacion de clases\n",
    "#b = 100\n",
    "#d = 010\n",
    "#f = 001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06703312",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (pd.read_csv(os.path.join(os.path.abspath(''),\"data\",\"distorsionadas\",'100','letras.csv'),sep=';',header=None)).to_numpy()\n",
    "#Convertimos el dataframe en array numpy\n",
    "data_train = data[:int(len(data)*0.8)]\n",
    "data_test = data[int(len(data)*0.8)+1:int(len(data)*0.8)+int(len(data)*0.15)]\n",
    "data_validation = data[int(len(data)*0.8)+int(len(data)*0.15)+1:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68562a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividiendo data train en una tupla (entrada,clase)\n",
    "letras_train = []\n",
    "for letra in data_train:\n",
    "    x_test = letra[:100]\n",
    "    y_test = letra[100:]\n",
    "    letras_train.append((x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a880c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W3 sin actualizar:\n",
      " [[0.02499537 0.56895597 0.9323185  0.64166249 0.62270712]\n",
      " [0.48015696 0.01276354 0.33316232 0.68266208 0.73841656]\n",
      " [0.89572861 0.26063442 0.23776221 0.11723033 0.3209823 ]]\n",
      "W2 sin actualizar:\n",
      " [[0.88765322 0.38568663 1.03329534 0.6391347  0.91002566]\n",
      " [0.59830298 0.09841071 1.02502697 0.27946655 0.53438245]\n",
      " [0.280924   0.31446202 0.12444915 0.97698835 1.02212681]\n",
      " [0.71421705 0.67357069 0.08781404 0.3543272  0.05285765]\n",
      " [0.58235775 0.55478154 0.19329764 0.85382843 0.25026197]]\n",
      "W3 actualizado:\n",
      " [[nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]]\n",
      "W2 actualizado:\n",
      " [[nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleoc\\AppData\\Local\\Temp\\ipykernel_14048\\583300128.py:78: RuntimeWarning: overflow encountered in multiply\n",
      "  new_weight.append(W1[j]+alfa*delta1*ys1)\n"
     ]
    }
   ],
   "source": [
    "print(\"W3 sin actualizar:\\n\",W3)\n",
    "print(\"W2 sin actualizar:\\n\",W2)\n",
    "#print(\"W1 sin actualizar:\\n\",W1)\n",
    "\n",
    "for i in range(80):\n",
    "\n",
    "    #Primer capa\n",
    "    ys1 =[]\n",
    "    for j in range(len(W1)):\n",
    "        #Suma ponderada\n",
    "        Z = np.dot(letras_train[i][0],W1[j])\n",
    "        #Funcion de activacion\n",
    "        ys1.append(lineal(Z+b))\n",
    "    #print(\"Primer capa: \", ys1)\n",
    "\n",
    "    #Segunda capa\n",
    "    ys2 = []\n",
    "    for j in range(len(W2)):\n",
    "        #Suma ponderada\n",
    "        Z = np.dot(ys1,W2[j])\n",
    "        #Funcion de activacion\n",
    "        ys2.append(sigmoide(Z+b))\n",
    "    #print(\"2da capa: \", ys2)\n",
    "    #Capa de salida\n",
    "    ys3 = []\n",
    "    for j in range(len(W3)):\n",
    "        #Suma ponderada\n",
    "        Z = np.dot(ys2,W3[j])\n",
    "        #Funcion de activacion\n",
    "        ys3.append(sigmoide(Z+b))\n",
    "    #print(\"Capa salida: \", ys3)\n",
    "    #!!-------Backpropagation-----!!\n",
    "    ys1 = np.array(ys1)\n",
    "    ys2 = np.array(ys2)\n",
    "    ys3 = np.array(ys3)\n",
    "    #Delta en capa 3\n",
    "    delta3 = []\n",
    "    for j in range(len(ys3)):\n",
    "        # error[j]*f'(a[j])\n",
    "        derivate_cost =-error(letras_train[i][1][j], ys3[j])\n",
    "        delta3.append(derivate_cost*derivate_sigmoide(ys3[j]))\n",
    "    \n",
    "    #Delta en capa 2\n",
    "    delta2 = []\n",
    "    W = np.transpose(W3)\n",
    "    for j in range(len(W)):\n",
    "        delta2.append(np.dot(W[j],delta3)*ys2[j])\n",
    "   \n",
    "    #Delta en capa oculta 1\n",
    "    delta1 = []\n",
    "    W = np.transpose(W2)\n",
    "    for j in range(len(W)):\n",
    "        delta1.append(np.dot(W[j],delta2)*ys1[j])\n",
    "   \n",
    "    \n",
    "    #!!---- Gradient descent -------!!\n",
    "    delta3 = np.array(delta3)\n",
    "    delta2 = np.array(delta2)\n",
    "    delta1 = np.array(delta1)\n",
    "    W3 = np.transpose(W3)\n",
    "    W2 = np.transpose(W2)\n",
    "    W1 = np.transpose(W1)\n",
    "    #Capa 3\n",
    "    new_weight = []\n",
    "    for j in range(len(W3)):\n",
    "        new_weight.append(W3[j]+alfa*delta3*ys3)\n",
    "    W3 = np.array(new_weight)\n",
    "    \n",
    "    #Capa 2\n",
    "    new_weight = []\n",
    "    for j in range(len(W2)):\n",
    "        new_weight.append(W2[j]+alfa*delta2*ys2)\n",
    "    W2 = np.array(new_weight)\n",
    "\n",
    "    #Capa 1\n",
    "    new_weight = []\n",
    "    for j in range(len(W1)):\n",
    "        new_weight.append(W1[j]+alfa*delta1*ys1)\n",
    "    W1 = np.array(new_weight)\n",
    "    #pesos actualizados\n",
    "    W3 = np.transpose(W3)\n",
    "    W2 = np.transpose(W2)\n",
    "    W1 = np.transpose(W1)\n",
    "\n",
    "print(\"W3 actualizado:\\n\",W3)\n",
    "print(\"W2 actualizado:\\n\",W2)\n",
    "#print(\"W1 actualizado:\\n\",W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7838c985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([400, 800, 600])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([1,2,3])\n",
    "B = np.array([4,4,2])\n",
    "result = 0\n",
    "for i in range(100):\n",
    "    result = result + A*B\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbbeb8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "y =[1,2,3,4]\n",
    "y = np.array(y)\n",
    "for i in reversed(y):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba23b61cdc6890bf9b74f0059fdc1fca5173150fee92ba939d36054f0efba838"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
