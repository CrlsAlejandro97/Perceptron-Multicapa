{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3637cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from function import lineal, sigmoide, derivate_sigmoide, derivate_lineal,Backpropagation, derivate_error\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d8d5462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializamos los pesos de la Capa 1\n",
    "w = np.random.random(500)\n",
    "w11 = w[:100]\n",
    "w12 = w[100:200]\n",
    "w13 = w[200:300]\n",
    "w14 = w[300:400]\n",
    "w15 = w[400:500]\n",
    "W1=[w11,w12,w13,w14,w15]\n",
    "\n",
    "#Inicializamos los pesos de la Capa 2\n",
    "w = np.random.random(25)\n",
    "w21 = w[:5]\n",
    "w22 = w[5:10]\n",
    "w23 = w[10:15]\n",
    "w24 = w[15:20]\n",
    "w25 = w[20:25]\n",
    "W2 = [w21,w22,w23,w24,w25] \n",
    "\n",
    "#Incializamos los pesos de la Capa 3\n",
    "w = np.random.random(15)\n",
    "w31 = w[:5]\n",
    "w32 = w[5:10]\n",
    "w33 = w[10:15]\n",
    "W3 = [w31,w32,w33]\n",
    "\n",
    "#Bias\n",
    "b = random.random()\n",
    "\n",
    "#Factor de aprendizaje\n",
    "alfa = random.random()\n",
    "\n",
    "#Codificacion de clases\n",
    "#b = 100\n",
    "#d = 010\n",
    "#f = 001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06703312",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (pd.read_csv(os.path.join(os.path.abspath(''),\"data\",\"distorsionadas\",'100','letras.csv'),sep=';',header=None)).to_numpy()\n",
    "#Convertimos el dataframe en array numpy\n",
    "data_train = data[:int(len(data)*0.8)]\n",
    "data_test = data[int(len(data)*0.8)+1:int(len(data)*0.8)+int(len(data)*0.15)]\n",
    "data_validation = data[int(len(data)*0.8)+int(len(data)*0.15)+1:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e68562a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividiendo data train en una tupla (entrada,clase)\n",
    "letras_train = []\n",
    "for letra in data_train:\n",
    "    x_test = letra[:100]\n",
    "    y_test = letra[100:]\n",
    "    letras_train.append((x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2a880c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1):\n",
    "\n",
    "    #Primer capa\n",
    "    ys1 =[]\n",
    "    for j in range(len(W1)):\n",
    "        #Suma ponderada\n",
    "        Z = np.dot(letras_train[i][0],W1[j])\n",
    "        #Funcion de activacion\n",
    "        ys1.append(lineal(Z+b))\n",
    "    #print(\"Primer capa: \", ys1)\n",
    "\n",
    "    #Segunda capa\n",
    "    ys2 = []\n",
    "    for j in range(len(W2)):\n",
    "        #Suma ponderada\n",
    "        Z = np.dot(ys1,W2[j])\n",
    "        #Funcion de activacion\n",
    "        ys2.append(lineal(Z+b))\n",
    "    #print(\"2da capa: \", ys2)\n",
    "    #Capa de salida\n",
    "    ys3 = []\n",
    "    for j in range(len(W3)):\n",
    "        #Suma ponderada\n",
    "        Z = np.dot(ys2,W3[j])\n",
    "        #Funcion de activacion\n",
    "        ys3.append(sigmoide(Z+b))\n",
    "    #print(\"Capa salida: \", ys3)\n",
    "\n",
    "    #!!-------Backpropagation-----!!\n",
    "    ys1 = np.array(ys1)\n",
    "    ys2 = np.array(ys2)\n",
    "    ys3 = np.array(ys3)\n",
    "    activations = [ys1,ys2,ys3]\n",
    "    W = [W1,W2,W3]\n",
    "    ye = letras_train[i][1]\n",
    "    deltas = Backpropagation(ye,activations,W[1:])\n",
    "    #!!----- Gradient descent------!!\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53dd8d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34345852 0.62651463 0.41141354 0.87224072 0.03973549 0.49186307\n",
      " 0.9334431  0.22548352 0.13078865 0.60048971 0.62077677 0.71745808\n",
      " 0.28913129 0.849145   0.12368099 0.94125955 0.01221701 0.30763972\n",
      " 0.31944135 0.57626734 0.65825585 0.58233993 0.47886528 0.01284347\n",
      " 0.32687522 0.70238533 0.98578172 0.31415145 0.3417053  0.17749606\n",
      " 0.39448786 0.12623617 0.10461626 0.4786433  0.29872189 0.21281594\n",
      " 0.69519048 0.67498452 0.33051367 0.15178633 0.3263234  0.06801051\n",
      " 0.35153065 0.21631981 0.66472352 0.68518464 0.78265117 0.82468296\n",
      " 0.43360991 0.31106661 0.87909701 0.48778608 0.6776916  0.79825249\n",
      " 0.42710277 0.33158918 0.18154205 0.36034092 0.49656002 0.1374573\n",
      " 0.71471551 0.87497369 0.92252666 0.72762764 0.272335   0.86011312\n",
      " 0.41199714 0.8331825  0.54893814 0.86826563 0.06370402 0.42556109\n",
      " 0.64731485 0.17824549 0.99679359 0.00486958 0.03938297 0.00485861\n",
      " 0.39285935 0.84048332 0.55210181 0.20748962 0.15782072 0.67212832\n",
      " 0.6161783  0.41027713 0.83107995 0.21731729 0.81151743 0.57652381\n",
      " 0.96231706 0.20331842 0.78265089 0.31980771 0.4577115  0.64800767\n",
      " 0.57576698 0.94286026 0.92731097 0.88803561]\n",
      "[0.97781866 0.80473177 0.58986018 0.30099223 0.75562662 0.47157364\n",
      " 0.77989342 0.72891815 0.99245594 0.96160526 0.73508202 0.84916261\n",
      " 0.44535146 0.88802666 0.34416971 0.06359635 0.15021434 0.69343903\n",
      " 0.82835727 0.92677689 0.38580619 0.02589615 0.85965053 0.85212228\n",
      " 0.68729018 0.86688208 0.17219238 0.60083819 0.87021931 0.86763991\n",
      " 0.08822614 0.24357683 0.70091039 0.05965698 0.08777592 0.58463439\n",
      " 0.45263657 0.03411927 0.8545416  0.14349071 0.01783812 0.92507707\n",
      " 0.61234901 0.58953142 0.83312598 0.62985867 0.84847702 0.53147432\n",
      " 0.2503771  0.54652211 0.40450543 0.3604356  0.1582728  0.1974405\n",
      " 0.18472722 0.09551761 0.83997491 0.72837545 0.02644214 0.26260551\n",
      " 0.35802075 0.81012557 0.31640235 0.304278   0.77134126 0.81960615\n",
      " 0.00516047 0.41293659 0.93819061 0.06736997 0.47866362 0.32164901\n",
      " 0.10690897 0.28311412 0.12306108 0.26995525 0.0355522  0.72373872\n",
      " 0.47000428 0.61854679 0.1479758  0.34878095 0.32720474 0.62336264\n",
      " 0.26536509 0.78222397 0.01063631 0.05519155 0.16671642 0.69351125\n",
      " 0.48904279 0.2849275  0.85505881 0.02645383 0.55534451 0.3680623\n",
      " 0.62418519 0.40345379 0.2379541  0.76970126]\n",
      "[0.44345948 0.30734817 0.67700458 0.7098132  0.43844939 0.90649047\n",
      " 0.46057781 0.56963323 0.04910531 0.03772472 0.90933396 0.82356273\n",
      " 0.03603189 0.64769303 0.99280811 0.50781098 0.71471613 0.13294092\n",
      " 0.70254267 0.19264912 0.03078534 0.78855066 0.50696224 0.20920601\n",
      " 0.71281373 0.2595052  0.42475209 0.1439138  0.43956771 0.37527767\n",
      " 0.93540686 0.14996861 0.25740752 0.88180929 0.47280475 0.58694172\n",
      " 0.67938921 0.09619925 0.97153641 0.87302603 0.80282255 0.51708654\n",
      " 0.97541471 0.84034764 0.60444999 0.64939692 0.62367916 0.92348795\n",
      " 0.65733773 0.73623525 0.25525728 0.39996111 0.65550418 0.85141225\n",
      " 0.97206226 0.98724449 0.18821145 0.02875289 0.48416776 0.38354934\n",
      " 0.70047347 0.50320877 0.75567504 0.36191095 0.22125832 0.23547016\n",
      " 0.81342817 0.57147688 0.27962965 0.53636688 0.74735455 0.82344342\n",
      " 0.62801941 0.9397756  0.31313666 0.68635527 0.11752983 0.18294389\n",
      " 0.61021963 0.36486643 0.55271628 0.33192937 0.135064   0.51697051\n",
      " 0.84093469 0.86528394 0.14648982 0.6473692  0.35320013 0.41734628\n",
      " 0.05465109 0.03497755 0.51648057 0.93203556 0.77129727 0.10469162\n",
      " 0.73847926 0.61919618 0.40067559 0.40611774]\n",
      "[4.63190936e-01 1.44111388e-01 2.32061316e-02 8.20497374e-04\n",
      " 4.20966078e-01 4.18860850e-01 3.29551541e-01 6.28027975e-01\n",
      " 7.89076694e-01 1.27357517e-01 4.42260449e-02 4.59655480e-01\n",
      " 8.13247666e-01 4.58950097e-01 1.61997652e-01 4.19457789e-01\n",
      " 4.67518847e-01 2.04944905e-01 4.78819351e-01 4.69621340e-01\n",
      " 9.99226947e-01 8.18102068e-01 2.52078400e-01 4.97869129e-01\n",
      " 8.79959606e-01 2.93536085e-01 5.18990794e-02 1.27368135e-01\n",
      " 4.76367439e-01 2.29971974e-01 5.63096090e-01 3.59885683e-02\n",
      " 3.66043596e-01 6.51999714e-01 4.86740274e-01 4.03580454e-01\n",
      " 7.82290411e-01 4.37462236e-01 7.96284674e-01 5.66046437e-01\n",
      " 7.16203730e-01 3.69996520e-01 3.57255629e-01 8.13637895e-01\n",
      " 1.10738908e-01 5.87218263e-01 8.81055038e-01 3.51966132e-01\n",
      " 9.37261084e-01 1.70840951e-01 8.67765581e-01 1.19871077e-01\n",
      " 8.33108646e-01 1.78405883e-01 4.96968165e-01 2.37248617e-01\n",
      " 8.54531326e-01 2.66325565e-01 5.26321966e-01 8.92986631e-01\n",
      " 9.16443916e-02 3.30559233e-01 5.08643106e-01 5.40438251e-01\n",
      " 9.71031586e-01 1.57030784e-02 9.66791853e-01 8.77883243e-03\n",
      " 9.53949842e-01 3.87952042e-01 9.11556983e-01 5.45180443e-01\n",
      " 2.82591034e-02 1.70924882e-01 6.45528741e-01 1.37400859e-01\n",
      " 2.09729391e-02 7.27864737e-01 5.21783936e-01 8.24761782e-01\n",
      " 5.95069599e-01 4.57445987e-01 5.12558170e-01 6.72198756e-01\n",
      " 5.86237648e-01 6.37705595e-01 4.94167978e-01 7.51828900e-01\n",
      " 8.80371448e-01 1.44967945e-01 6.00681265e-01 9.92329164e-01\n",
      " 3.14264932e-01 2.48560622e-01 1.66904790e-01 5.70425517e-01\n",
      " 2.73402118e-01 6.71100950e-01 2.65655561e-01 1.17507054e-01]\n",
      "[0.95524873 0.72994103 0.14835369 0.83176491 0.27529724 0.05243094\n",
      " 0.01521171 0.68456394 0.16416742 0.92625252 0.4435729  0.5166438\n",
      " 0.4401585  0.37778741 0.795975   0.83905819 0.22904241 0.71749055\n",
      " 0.57962963 0.9001111  0.6862174  0.35147808 0.25093775 0.14009798\n",
      " 0.71105755 0.68832584 0.16677673 0.97491019 0.40189485 0.80374357\n",
      " 0.32369404 0.51602422 0.84828653 0.18282114 0.59198537 0.60301702\n",
      " 0.40803265 0.12181171 0.10192808 0.27057908 0.39983469 0.22838313\n",
      " 0.49875363 0.83535553 0.30355169 0.02212261 0.57759288 0.37673101\n",
      " 0.74973335 0.88369893 0.48016236 0.99223919 0.34326268 0.17721102\n",
      " 0.5340675  0.76421231 0.88276587 0.6267012  0.2900196  0.44568379\n",
      " 0.1115807  0.57225901 0.0681999  0.62911673 0.3073756  0.61738895\n",
      " 0.55226134 0.23303398 0.52738745 0.43238418 0.44286752 0.67085628\n",
      " 0.13567092 0.24661482 0.47188881 0.90417312 0.88001995 0.58741988\n",
      " 0.97718654 0.95111679 0.13588792 0.35234417 0.76349666 0.36572153\n",
      " 0.84339737 0.23313915 0.86262068 0.84742457 0.38771751 0.81048798\n",
      " 0.7083653  0.17296188 0.36524596 0.63783974 0.79067479 0.29330499\n",
      " 0.91201075 0.17545852 0.36040699 0.55435538]\n",
      "[0.29219303 0.24416771 0.86726795 0.56652078 0.61626316]\n",
      "[0.26550772 0.48754927 0.84175869 0.08597616 0.34930937]\n",
      "[0.47156013 0.38379318 0.66253853 0.88666264 0.75874282]\n",
      "[0.46474058 0.42972743 0.06545207 0.24880261 0.68696549]\n",
      "[0.63249864 0.03215891 0.22342973 0.81013789 0.33679207]\n",
      "[0.08738497 0.67162131 0.04610888 0.48577686 0.26459115]\n",
      "[0.13174198 0.34989219 0.83312505 0.82345104 0.9703699 ]\n",
      "[0.21955606 0.1703027  0.15649485 0.60691104 0.5170356 ]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for w in W:\n",
    " x,y = w.shape\n",
    " for j in range(x):\n",
    "    for k in range(k):\n",
    "        w[j][k] -= activations[i][k]*deltas[i][j]*alfa*0.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba23b61cdc6890bf9b74f0059fdc1fca5173150fee92ba939d36054f0efba838"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
