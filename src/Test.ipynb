{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from functionsMaths import calculateDelta, get_mse,gradiente_descendente, feedforward, div_tuplas, init_params_test\n",
    "import os\n",
    "import math\n",
    "from statistics import mean\n",
    "from Distorsionador import Distorsionador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializamos los pesos de la Capa 1\n",
    "w = np.random.random(500)\n",
    "w11 = w[:100]\n",
    "w12 = w[100:200]\n",
    "w13 = w[200:300]\n",
    "w14 = w[300:400]\n",
    "w15 = w[400:500]\n",
    "W1=[w11,w12,w13,w14,w15]\n",
    "\n",
    "\n",
    "#Inicializamos los pesos de la Capa 2\n",
    "w = np.random.random(25)\n",
    "w21 = w[:5]\n",
    "w22 = w[5:10]\n",
    "w23 = w[10:15]\n",
    "w24 = w[15:20]\n",
    "w25 = w[20:25]\n",
    "W2 = [w21,w22,w23,w24,w25] \n",
    "\n",
    "\n",
    "#Incializamos los pesos de la Capa 3\n",
    "w = np.random.random(15)\n",
    "w31 = w[:5]\n",
    "w32 = w[5:10]\n",
    "w33 = w[10:15]\n",
    "W3 = [w31,w32,w33]\n",
    "\n",
    "#Conversiones\n",
    "W1 = np.array(W1)\n",
    "W2 = np.array(W2)\n",
    "W3 = np.array(W3)\n",
    "W = [W1,W2,W3]\n",
    "\n",
    "\n",
    "#Bias\n",
    "b = [random.random() for i in range(13)]\n",
    "b1= b[:5]\n",
    "b2 = b[5:10]\n",
    "b3 = b [10:]\n",
    "B = [b1,b2,b3]\n",
    "\n",
    "#Factor de aprendizaje\n",
    "alfa = np.array(random.random())\n",
    "beta = np.array(random.random())\n",
    "\n",
    "#Codificacion de clases\n",
    "#b = 100\n",
    "#d = 010\n",
    "#f = 001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad =['100','500','1000']\n",
    "set_validation = [0.1,0.2,0.3]\n",
    "epocas = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dejando fijo 2 capas ocultas con 5 neuronas c/u\n",
    "rows = []\n",
    "for set in range (len(cantidad)):\n",
    "    for percentage in range(len(set_validation)):\n",
    "        \n",
    "     data = (pd.read_csv(os.path.join(os.path.abspath(''),\"data\",\"distorsionadas\",cantidad[set],'letras.csv'),sep=';',header=None)).to_numpy()\n",
    "     #Convertimos el dataframe en array numpy\n",
    "     data_train = data[:int(len(data)-int(len(data)*set_validation[percentage])*2)]\n",
    "     data_validation = data[int(len(data)-int(len(data)*set_validation[percentage])*2):int(len(data)-int(len(data)*set_validation[percentage])*2)+int(len(data)*set_validation[percentage])]\n",
    "     data_test = data[int(len(data)-int(len(data)*set_validation[percentage])*2)+int(len(data)*set_validation[percentage]):]\n",
    "\n",
    "     #Division de datos en tuplas(datos,clase)\n",
    "     letras_train = div_tuplas(data_train)\n",
    "     letras_test = div_tuplas(data_train)\n",
    "     letras_validation = div_tuplas(data_validation)\n",
    "\n",
    "\n",
    "     #Comienzo de Perceptron\n",
    "     err_train_epoc = 0\n",
    "     err_valid_epoc = 0\n",
    "\n",
    "     for epoc in range(epocas):\n",
    "         err_training = np.array([0,0,0])\n",
    "         err_validation = np.array([0,0,0])\n",
    "    \n",
    "         for i in range(len(letras_train)):\n",
    "        \n",
    "             #TRAINING\n",
    "             Y = feedforward(letras_train[i][0],W,B)\n",
    "             Ye = np.array(letras_train[i][1])\n",
    "             err_training = err_training + ((Ye-Y[-1])**2)\n",
    "\n",
    "             #Deltas\n",
    "             deltas = calculateDelta(Y[-1],Ye,W[1:])\n",
    "\n",
    "             W,B = gradiente_descendente(W,B,deltas,Y[0:3],alfa,beta)\n",
    "             W1 = W[0]\n",
    "             W2 = W[1]\n",
    "             W3 = W[2]\n",
    "             b1 = B[0]\n",
    "             b2 = B[1]\n",
    "             b3 = B[2]\n",
    "\n",
    "         #VALIDATION\n",
    "         for i in range(len(letras_validation)):\n",
    "             Y = feedforward(letras_validation[i][0],W,B)\n",
    "             Ye = np.array(letras_validation[i][1])\n",
    "             err_validation = err_validation + ((Ye-Y[-1])**2)\n",
    "\n",
    "         err_train_epoc = get_mse(np.mean(err_training),len(letras_train))\n",
    "         err_valid_epoc = get_mse(np.mean(err_validation),len(letras_validation))\n",
    "         rows.append([epoc,cantidad[set],str(set_validation[percentage]*100)+' %',err_train_epoc,err_valid_epoc])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoc</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "      <th>error training</th>\n",
       "      <th>error validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>10.0 %</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>20.0 %</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30.0 %</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>10.0 %</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>20.0 %</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>30.0 %</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>10.0 %</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>20.0 %</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>30.0 %</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoc count percentage  error training  error validation\n",
       "0     0   100     10.0 %        0.000031          0.000629\n",
       "1     0   100     20.0 %        0.000036          0.000006\n",
       "2     0   100     30.0 %        0.000021          0.000043\n",
       "3     0   500     10.0 %        0.000048          0.000709\n",
       "4     0   500     20.0 %        0.000042          0.000032\n",
       "5     0   500     30.0 %        0.000012          0.000076\n",
       "6     0  1000     10.0 %        0.000042          0.000110\n",
       "7     0  1000     20.0 %        0.000022          0.000069\n",
       "8     0  1000     30.0 %        0.000019          0.000032"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla = pd.DataFrame(rows,columns=['epoc','count','percentage','error training','error validation'])\n",
    "tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La cantidad de capas ocultas esta determinado por el vector layer; \n",
    "# [5,5] = 2 capas de 5 neuronas c/u\n",
    "#[5] = 1 capa de 5 neuronas\n",
    "#layers = [5,5]\n",
    "test =[ [[5],0.5,0.5], [[10],0.5,0.5], [[5,5],0.5,0.5], [[10,10],0.5,0.5]]\n",
    "\n",
    "#Inicializando Arquitectura\n",
    "#W,B = init_params_test(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for set in range (len(cantidad)):\n",
    "    for percentage in range(len(set_validation)):\n",
    "        \n",
    "     data = (pd.read_csv(os.path.join(os.path.abspath(''),\"data\",\"distorsionadas\",cantidad[set],'letras.csv'),sep=';',header=None)).to_numpy()\n",
    "     #Convertimos el dataframe en array numpy\n",
    "     data_train = data[:int(len(data)-int(len(data)*set_validation[percentage])*2)]\n",
    "     data_validation = data[int(len(data)-int(len(data)*set_validation[percentage])*2):int(len(data)-int(len(data)*set_validation[percentage])*2)+int(len(data)*set_validation[percentage])]\n",
    "     data_test = data[int(len(data)-int(len(data)*set_validation[percentage])*2)+int(len(data)*set_validation[percentage]):]\n",
    "\n",
    "     #Division de datos en tuplas(datos,clase)\n",
    "     letras_train = div_tuplas(data_train)\n",
    "     letras_test = div_tuplas(data_train)\n",
    "     letras_validation = div_tuplas(data_validation)\n",
    "\n",
    "\n",
    "     #Comienzo de Perceptron\n",
    "     err_train_epoc = 0\n",
    "     err_valid_epoc = 0\n",
    "\n",
    "     for epoc in range(epocas):\n",
    "         err_training = np.array([0,0,0])\n",
    "         err_validation = np.array([0,0,0])\n",
    "    \n",
    "         for i in range(len(letras_train)):\n",
    "        \n",
    "             #TRAINING\n",
    "             Y = feedforward(letras_train[i][0],W,B)\n",
    "             Ye = np.array(letras_train[i][1])\n",
    "             err_training = err_training + ((Ye-Y[-1])**2)\n",
    "\n",
    "             #Deltas\n",
    "             deltas = calculateDelta(Y[-1],Ye,W[1:])\n",
    "\n",
    "             W,B = gradiente_descendente(W,B,deltas,Y[0:3],alfa,beta)\n",
    "             W1 = W[0]\n",
    "             W2 = W[1]\n",
    "             W3 = W[2]\n",
    "             b1 = B[0]\n",
    "             b2 = B[1]\n",
    "             b3 = B[2]\n",
    "\n",
    "         #VALIDATION\n",
    "         for i in range(len(letras_validation)):\n",
    "             Y = feedforward(letras_validation[i][0],W,B)\n",
    "             Ye = np.array(letras_validation[i][1])\n",
    "             err_validation = err_validation + ((Ye-Y[-1])**2)\n",
    "\n",
    "         err_train_epoc = get_mse(np.mean(err_training),len(letras_train))\n",
    "         err_valid_epoc = get_mse(np.mean(err_validation),len(letras_validation))\n",
    "         rows.append([epoc,cantidad[set],str(set_validation[percentage]*100)+' %',err_train_epoc,err_valid_epoc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoc</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "      <th>error training</th>\n",
       "      <th>error validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>10.0 %</td>\n",
       "      <td>0.171956</td>\n",
       "      <td>0.135825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>20.0 %</td>\n",
       "      <td>0.125250</td>\n",
       "      <td>0.114514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30.0 %</td>\n",
       "      <td>0.113962</td>\n",
       "      <td>0.112683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>10.0 %</td>\n",
       "      <td>0.112374</td>\n",
       "      <td>0.108406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>20.0 %</td>\n",
       "      <td>0.111297</td>\n",
       "      <td>0.110686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>30.0 %</td>\n",
       "      <td>0.109516</td>\n",
       "      <td>0.109087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>10.0 %</td>\n",
       "      <td>0.084633</td>\n",
       "      <td>0.064189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>20.0 %</td>\n",
       "      <td>0.055523</td>\n",
       "      <td>0.056542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>30.0 %</td>\n",
       "      <td>0.053254</td>\n",
       "      <td>0.054300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoc count percentage  error training  error validation\n",
       "0     0   100     10.0 %        0.171956          0.135825\n",
       "1     0   100     20.0 %        0.125250          0.114514\n",
       "2     0   100     30.0 %        0.113962          0.112683\n",
       "3     0   500     10.0 %        0.112374          0.108406\n",
       "4     0   500     20.0 %        0.111297          0.110686\n",
       "5     0   500     30.0 %        0.109516          0.109087\n",
       "6     0  1000     10.0 %        0.084633          0.064189\n",
       "7     0  1000     20.0 %        0.055523          0.056542\n",
       "8     0  1000     30.0 %        0.053254          0.054300"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla = pd.DataFrame(rows,columns=['epoc','count','percentage','error training','error validation'])\n",
    "tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =[ [[5],0.5,0.5], [[10],0.5,0.5], [[5,5],0.5,0.5], [[10,10],0.5,0.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (pd.read_csv(os.path.join(os.path.abspath(''),\"data\",\"distorsionadas\",'100','letras.csv'),sep=';',header=None)).to_numpy()\n",
    "#Convertimos el dataframe en array numpy\n",
    "data_train = data[:int(len(data)*0.8)]\n",
    "data_test = data[int(len(data)*0.8)+1:int(len(data)*0.8)+int(len(data)*0.15)]\n",
    "data_validation = data[int(len(data)*0.8)+int(len(data)*0.15)+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Division de datos en tuplas(datos,clase)\n",
    "letras_train = div_tuplas(data_train)\n",
    "letras_test = div_tuplas(data_train)\n",
    "letras_validation = div_tuplas(data_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aleoc\\OneDrive\\Escritorio\\Perceptron-Multicapa\\src\\Test.ipynb Celda 14\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aleoc/OneDrive/Escritorio/Perceptron-Multicapa/src/Test.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m m \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(test[\u001b[39m0\u001b[39m][\u001b[39m2\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aleoc/OneDrive/Escritorio/Perceptron-Multicapa/src/Test.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m Y \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aleoc/OneDrive/Escritorio/Perceptron-Multicapa/src/Test.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m Y \u001b[39m=\u001b[39m feedforward(letras_train[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m],W,B)\n",
      "File \u001b[1;32mc:\\Users\\aleoc\\OneDrive\\Escritorio\\Perceptron-Multicapa\\src\\functionsMaths.py:109\u001b[0m, in \u001b[0;36mfeedforward\u001b[1;34m(x, w, b)\u001b[0m\n\u001b[0;32m    107\u001b[0m yi \u001b[39m=\u001b[39m []\n\u001b[0;32m    108\u001b[0m zi \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 109\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(w[i])):\n\u001b[0;32m    110\u001b[0m     \u001b[39m#Suma ponderada\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     entrada \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(y[i],w[i][j])\n\u001b[0;32m    112\u001b[0m     \u001b[39m#Funcion de activacion\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "W,B = init_params_test(test[0][0])\n",
    "lr = np.array(test[0][1])\n",
    "m = np.array(test[0][2])\n",
    "Y = []\n",
    "Y = feedforward(letras_train[0][0],W,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aleoc\\OneDrive\\Escritorio\\Perceptron-Multicapa\\src\\Test.ipynb Celda 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aleoc/OneDrive/Escritorio/Perceptron-Multicapa/src/Test.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m#TRAINING\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aleoc/OneDrive/Escritorio/Perceptron-Multicapa/src/Test.ipynb#X11sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(letras_train)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aleoc/OneDrive/Escritorio/Perceptron-Multicapa/src/Test.ipynb#X11sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     Y \u001b[39m=\u001b[39m feedforward(letras_train[i][\u001b[39m0\u001b[39;49m],W,B)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aleoc/OneDrive/Escritorio/Perceptron-Multicapa/src/Test.ipynb#X11sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     Ye \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(letras_train[i][\u001b[39m1\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aleoc/OneDrive/Escritorio/Perceptron-Multicapa/src/Test.ipynb#X11sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     err_training \u001b[39m=\u001b[39m err_training \u001b[39m+\u001b[39m ((Ye\u001b[39m-\u001b[39mY[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aleoc\\OneDrive\\Escritorio\\Perceptron-Multicapa\\src\\functionsMaths.py:109\u001b[0m, in \u001b[0;36mfeedforward\u001b[1;34m(x, w, b)\u001b[0m\n\u001b[0;32m    107\u001b[0m yi \u001b[39m=\u001b[39m []\n\u001b[0;32m    108\u001b[0m zi \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 109\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(w[i])):\n\u001b[0;32m    110\u001b[0m     \u001b[39m#Suma ponderada\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     entrada \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(y[i],w[i][j])\n\u001b[0;32m    112\u001b[0m     \u001b[39m#Funcion de activacion\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for nro in range(len(test)):\n",
    "    #architecture\n",
    "    W,B = init_params_test(test[nro][0])\n",
    "    lr = np.array(test[nro][1])\n",
    "    m = np.array(test[nro][2])\n",
    "    Y = []\n",
    "    for set in range (len(cantidad)):\n",
    "        for percentage in range(len(set_validation)):\n",
    "        \n",
    "            data = (pd.read_csv(os.path.join(os.path.abspath(''),\"data\",\"distorsionadas\",cantidad[set],'letras.csv'),sep=';',header=None)).to_numpy()\n",
    "            #Convertimos el dataframe en array numpy\n",
    "            data_train = data[:int(len(data)-int(len(data)*set_validation[percentage])*2)]\n",
    "            data_validation = data[int(len(data)-int(len(data)*set_validation[percentage])*2):int(len(data)-int(len(data)*set_validation[percentage])*2)+int(len(data)*set_validation[percentage])]\n",
    "            data_test = data[int(len(data)-int(len(data)*set_validation[percentage])*2)+int(len(data)*set_validation[percentage]):]\n",
    "\n",
    "            #Division de datos en tuplas(datos,clase)\n",
    "            letras_train = div_tuplas(data_train)\n",
    "            letras_test = div_tuplas(data_train)\n",
    "            letras_validation = div_tuplas(data_validation)\n",
    "\n",
    "\n",
    "            #Comienzo de Perceptron\n",
    "            err_train_epoc = 0\n",
    "            err_valid_epoc = 0\n",
    "\n",
    "            for epoc in range(epocas):\n",
    "                err_training = np.array([0,0,0])\n",
    "                err_validation = np.array([0,0,0])\n",
    "\n",
    "                #TRAINING\n",
    "                for i in range(len(letras_train)):\n",
    "        \n",
    "                    Y = feedforward(letras_train[i][0],W,B)\n",
    "                    Ye = np.array(letras_train[i][1])\n",
    "                    err_training = err_training + ((Ye-Y[-1])**2)\n",
    "\n",
    "                    #Deltas\n",
    "                    deltas = calculateDelta(Y[-1],Ye,W[1:])\n",
    "\n",
    "                    W,B = gradiente_descendente(W,B,deltas,Y[0:len(Y)-1],alfa,beta)\n",
    "                    # W1 = W[0]\n",
    "                    # W2 = W[1]\n",
    "                    # W3 = W[2]\n",
    "                    # b1 = B[0]\n",
    "                    # b2 = B[1]\n",
    "                    # b3 = B[2]\n",
    "\n",
    "                #VALIDATION\n",
    "                for i in range(len(letras_validation)):\n",
    "                    Y = feedforward(letras_validation[i][0],W,B)\n",
    "                    Ye = np.array(letras_validation[i][1])\n",
    "                err_validation = err_validation + ((Ye-Y[-1])**2)\n",
    "\n",
    "            err_train_epoc = get_mse(np.mean(err_training),len(letras_train))\n",
    "            err_valid_epoc = get_mse(np.mean(err_validation),len(letras_validation))\n",
    "            rows.append([len(test[nro][0]),test[nro][0][0],epoc,cantidad[set],str(set_validation[percentage]*100)+' %',err_train_epoc,err_valid_epoc])\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = pd.DataFrame(rows,columns=['count layer hidden','count neuron','epoc','count','percentage','error training','error validation'])\n",
    "tabla"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba23b61cdc6890bf9b74f0059fdc1fca5173150fee92ba939d36054f0efba838"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
