{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ef9daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from function import lineal, sigmoide\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d4fe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "letras_100 = pd.read_csv(\"data/distorsionadas/100/letras.csv\",sep=';',header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e129d0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "letras_train_porc = 0.8\n",
    "letras_test_porc = 0.15\n",
    "\n",
    "cant_letras_train = int(len(letras_100)*letras_train_porc)\n",
    "cant_letras_test = int(len(letras_100)*letras_test_porc)\n",
    "\n",
    "letras_train = letras_100[:cant_letras_train]\n",
    "letras_test = letras_100[cant_letras_train+1:cant_letras_train+cant_letras_test]\n",
    "letras_validation = letras_100[cant_letras_train+cant_letras_test+1:]\n",
    "\n",
    "# El set de validación se utilizará durante iteraciones que haremos con el conjunto de entrenamiento.\n",
    "\n",
    "\n",
    "#Generar los conjuntos de entrenamiento, validacion y test\n",
    "\n",
    "data_train = []\n",
    "for letra in letras_train:\n",
    "    x_train = letra[:100]\n",
    "    y_train = letra[100:]\n",
    "    data_train.append((x_train, y_train))\n",
    "\n",
    "\n",
    "data_test = []\n",
    "for letra in letras_test:\n",
    "    x_test = letra[:100]\n",
    "    y_test = letra[100:]\n",
    "    data_test.append((x_test, y_test))\n",
    "\n",
    "data_validation = []\n",
    "for letra in letras_validation:\n",
    "    x_validation = letra[:100]\n",
    "    y_validation = letra[100:]\n",
    "    data_validation.append((x_validation, y_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c6e0433",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CONFIGURACION DEL PERCEPTRON\"\"\"\n",
    "\n",
    "\n",
    "cant_capas_ocultas = 2\n",
    "coeficiente_aprendizaje = 0.4\n",
    "momento = 0.7\n",
    "\n",
    "#Cantidades de neuronas por cada capa\n",
    "\n",
    "cant_ce = 100\n",
    "cant_cs = 3\n",
    "cant_c1 = 5\n",
    "cant_c2 = 5\n",
    "\n",
    "#Capa de entrada, se los inicializa en 0\n",
    "\n",
    "ce = np.zeros(cant_ce, dtype=int)\n",
    "\n",
    "\n",
    "#Capa de salida\n",
    "\n",
    "cs = np.zeros(cant_cs, dtype=int)\n",
    "\n",
    "cs = {}\n",
    "for n in range(cant_cs):\n",
    "    cs[n] = {\n",
    "        \"x\": 0,\n",
    "        \"y\": 0\n",
    "    }\n",
    "\n",
    "#Primera capa oculta\n",
    "\n",
    "c1 = np.zeros(cant_c1, dtype=int)\n",
    "c1 = {}\n",
    "for n in range(cant_c1):\n",
    "    c1[n] = {\n",
    "        \"x\": 0,\n",
    "        \"y\": 0\n",
    "    }\n",
    "\n",
    "#Segunda capa oculta\n",
    "\n",
    "c2 = np.zeros(cant_c2, dtype=int)\n",
    "c2 = {}\n",
    "for n in range(cant_c2):\n",
    "    c2[n] = {\n",
    "        \"x\": 0,\n",
    "        \"y\": 0\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "#Inicializamos los pesos (100 por cada neurona, tenemos 5 neuronas)\n",
    "\n",
    "\n",
    "\n",
    "#Cantidades de pesos\n",
    "\n",
    "cant_pesos = cant_ce*cant_c1 + cant_c1*cant_c2 + cant_c2*cant_cs\n",
    "\n",
    "\n",
    "#Codificacion de como se va a representar la salida de cada letra\n",
    "\n",
    "y = {\n",
    "    'b': [1, 0, 0],\n",
    "    'd': [0, 1, 0],\n",
    "    'f': [0, 0, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ac6e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.random.rand(5, 100)\n",
    "w2 = np.random.rand(5, 5)\n",
    "w3 = np.random.rand(3, 5)\n",
    "\n",
    "#Bias\n",
    "b1 = random.random()\n",
    "b2 = random.random()\n",
    "b3 = random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0260b730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1:  [ 8.37962418 10.65749025  9.84919801 10.40323024  8.22469768]\n",
      "a1:  [0.83796242 1.06574902 0.9849198  1.04032302 0.82246977]\n",
      "z2:  [1.710517   3.37122331 1.52275316 2.69298064 3.05379935]\n",
      "a2:  [0.1710517  0.33712233 0.15227532 0.26929806 0.30537994]\n",
      "z3:  [1.25940733 1.18706235 1.22233721]\n",
      "a3:  [0.77892407 0.76621526 0.77247459]\n",
      "y:  [1 0 0]\n",
      "Costo total 1.0\n"
     ]
    }
   ],
   "source": [
    "for letra in data_train[:1]:\n",
    "    x = letra[0] \n",
    "    y = letra[1]\n",
    "    Z1 = w1.dot(x) + b1\n",
    "    A1 = lineal(Z1)\n",
    "    Z2 = w2.dot(A1) + b2\n",
    "    A2 = lineal(Z2)\n",
    "    Z3 = (w3.dot(A2) + b3)\n",
    "    A3 = sigmoide(Z3)\n",
    "    Y = np.zeros_like(A3, dtype=int)\n",
    "    Y[A3.argmax(0)] = 1     \n",
    "    print(\"z1: \", Z1)\n",
    "    print(\"a1: \", A1)\n",
    "    print(\"z2: \", Z2)\n",
    "    print(\"a2: \",A2)\n",
    "    print(\"z3: \",Z3)\n",
    "    print(\"a3: \",A3)\n",
    "    print(\"y: \",Y)\n",
    "    #e: Resta entre los outputs obtenidos y los deseados\n",
    "    e = Y - y\n",
    "    cost = 0\n",
    "    for i in range(len(Y)):\n",
    "        cost+=0.5*(e[i])**2\n",
    "    print(\"Costo total\", cost)\n",
    "    \n",
    "    print(\"Pesos antes de backpropagation: \", w3)\n",
    "    w3 = w3 - coeficiente_aprendizaje"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
